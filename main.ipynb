{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjSRYFvWb/8Ka1LKn5ZkRz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancescoI/RecoUtils/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6dKyGRMXZgM",
        "outputId": "6942acc3-f825-4529-89f0-aa4e3ff98f64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iRB3DYyPa5-"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import scipy.sparse as sp\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMMduOxXfgxx"
      },
      "source": [
        "def gpu(tensor, gpu=False):\n",
        "\n",
        "    if gpu:\n",
        "        return tensor.cuda()\n",
        "    else:\n",
        "        return tensor\n",
        "\n",
        "\n",
        "def cpu(tensor):\n",
        "\n",
        "    if tensor.is_cuda:\n",
        "        return tensor.cpu()\n",
        "    else:\n",
        "        return tensor"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWCLjrSlQcJv"
      },
      "source": [
        "### Loss"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx5YWDe-QdLe"
      },
      "source": [
        "def hinge_loss(positive, negative):\n",
        "    \n",
        "    loss = torch.clamp(negative - positive + 1.0, 0.0)\n",
        "\n",
        "    return loss.mean()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZqTTsToP8VS"
      },
      "source": [
        "### Utilities"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq4g1zHhP9nH"
      },
      "source": [
        "def get_negative_batch(batch, n_items, item_to_metadata_dict):\n",
        "    \n",
        "    neg_batch = None\n",
        "\n",
        "    neg_item_id = np.random.randint(0, n_items-1, len(batch))\n",
        "    \n",
        "    if item_to_metadata_dict:\n",
        "        neg_metadata_id = [item_to_metadata_dict[item] for item in neg_item_id]    \n",
        "    else:\n",
        "        neg_metadata_id = None\n",
        "    \n",
        "    neg_batch = pd.concat([neg_batch, pd.DataFrame({'user_id': batch['user_id'],\n",
        "                                                    'item_id': neg_item_id, \n",
        "                                                    'metadata': neg_metadata_id})])\n",
        "            \n",
        "    return neg_batch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mhWqe6JQP72"
      },
      "source": [
        "class Dataset():\n",
        "    \n",
        "    def __init__(self, brand):\n",
        "        \n",
        "        self.brand = brand\n",
        "    \n",
        "    def _get_interactions(self):\n",
        "\n",
        "        bucket_uri = f'/content/drive/My Drive/'\n",
        "\n",
        "        if self.brand == 'missoni':\n",
        "        \n",
        "          dataset = pd.read_csv(bucket_uri + f'{self.brand}.csv')\n",
        "\n",
        "\n",
        "        elif self.brand == 'ton':\n",
        "          \n",
        "          clickstream = pd.read_csv(bucket_uri + f'{self.brand}.csv')\n",
        "          metadata = pd.read_csv(bucket_uri + 'anagrafica_ton.csv')\n",
        "\n",
        "          clickstream = (clickstream\\\n",
        "                         .groupby(['user_ids', 'product_code'])['brand'].count() \n",
        "                         ).reset_index()\n",
        "          \n",
        "          clickstream.columns = ['hashedEmail', 'product', 'actions']\n",
        "\n",
        "          dataset = pd.merge(clickstream, metadata, left_on='product', right_on='pty_pim_variant')\n",
        "          \n",
        "          dataset = dataset[['hashedEmail', 'product', 'macro', 'saleline', 'actions']]\n",
        "          dataset.columns = ['hashedEmail', 'product', 'macro', 'saleLine', 'actions']\n",
        "\n",
        "          dataset['gender'] = 'W'\n",
        "\n",
        "        return dataset \n",
        "    \n",
        "    \n",
        "    def _encondig_label(self, dataset, input_col, output_col):\n",
        "        \n",
        "        encoder = LabelEncoder()\n",
        "        dataset[output_col] = encoder.fit(dataset[input_col]).transform(dataset[input_col])\n",
        "        \n",
        "        return dataset, encoder\n",
        "    \n",
        "    \n",
        "    def fit(self, metadata=None, seasons=None):\n",
        "        \n",
        "        dataset = self._get_interactions()\n",
        "        self.metadata = metadata\n",
        "        \n",
        "        if seasons:\n",
        "            dataset = dataset[dataset['season'].isin(seasons)]\n",
        "        \n",
        "        ### Label Encoding\n",
        "        dataset, _ = self._encondig_label(dataset, input_col='hashedEmail', output_col='user_id')\n",
        "        dataset, _ = self._encondig_label(dataset, input_col='product', output_col='item_id')\n",
        "        \n",
        "        if metadata is not None:\n",
        "            output_list_name = []\n",
        "            \n",
        "            for meta in metadata:\n",
        "                output_name = meta + '_id'\n",
        "                dataset, _ = self._encondig_label(dataset, input_col=meta, output_col=output_name)\n",
        "                output_list_name.append(output_name)                \n",
        "            \n",
        "            dataset['metadata'] = dataset[output_list_name].values.tolist()\n",
        "            self.metadata_id = output_list_name\n",
        "            \n",
        "        self.dataset = dataset\n",
        "        \n",
        "    def get_item_metadata_dict(self):\n",
        "        \n",
        "        if self.metadata is not None:\n",
        "        \n",
        "            return self.dataset.set_index('item_id')['metadata'].to_dict()\n",
        "        \n",
        "        else:\n",
        "            \n",
        "            return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv7ONQu8P3-l"
      },
      "source": [
        "### Evaluate"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN5JU_vlP5UI"
      },
      "source": [
        "def auc_score(positive, negative):\n",
        "    \n",
        "    total_auc = []\n",
        "    \n",
        "    positive = positive.cpu().detach().numpy()\n",
        "    negative = negative.cpu().detach().numpy()\n",
        "\n",
        "    batch_auc = (positive > negative).sum() / len(positive)\n",
        "    total_auc.append(batch_auc)\n",
        "        \n",
        "    return np.mean(total_auc)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em05GKUsQAT8"
      },
      "source": [
        "def evaluate(model):\n",
        "    \n",
        "    ### TRAIN    \n",
        "    negative_train = get_negative_batch(batch=model.train, n_items=model.dataset.dataset['item_id'].max(), item_to_metadata_dict=None)\n",
        "    negative_train.columns = ['user_id', 'item_id_neg', 'metadata_neg']\n",
        "    \n",
        "    merged_train = pd.concat([model.train, negative_train], axis=1)\n",
        "    \n",
        "    train_auc = []\n",
        "    \n",
        "    for row in merged_train.itertuples():\n",
        "        \n",
        "        score = np.sum(model.pred[row.user_id, row.item_id] > model.pred[row.user_id, row.item_id_neg])\n",
        "        train_auc.append(score)\n",
        "    \n",
        "    ### TEST\n",
        "    negative_test = get_negative_batch(batch=model.test, n_items=model.dataset.dataset['item_id'].max(), item_to_metadata_dict=None)\n",
        "    negative_test.columns = ['user_id', 'item_id_neg', 'metadata_neg']\n",
        "    merged_test = pd.concat([model.test, negative_test], axis=1)\n",
        "    \n",
        "    test_auc = []\n",
        "    \n",
        "    for row in merged_test.itertuples():\n",
        "        \n",
        "        score = np.sum(model.pred[row.user_id, row.item_id] > model.pred[row.user_id, row.item_id_neg])\n",
        "        test_auc.append(score)\n",
        "    \n",
        "    print(f'Train AUC: {np.sum(train_auc) / merged_train.shape[0]}')\n",
        "    print(f'Test AUC: {np.sum(test_auc) / merged_test.shape[0]}')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocus4Q3oQCmL"
      },
      "source": [
        "def precision_recall_k(model, k):\n",
        "    \n",
        "    ### TRAIN\n",
        "    values = np.ones(model.train.shape[0])\n",
        "    users = model.train.loc[:, 'user_id']\n",
        "    items = model.train.loc[:, 'item_id']\n",
        "    \n",
        "    sparse_matrix = sp.csr_matrix((values, (users, items)))\n",
        "    \n",
        "    matrix = sparse_matrix.toarray()\n",
        "    total_precision = []\n",
        "    total_recall = []\n",
        "    \n",
        "    for index, row in enumerate(matrix):\n",
        "        \n",
        "        truth = np.nonzero(row)[0]\n",
        "        if len(truth) > 0:\n",
        "            prediction = np.argsort(-model.pred[index, :])[:k]\n",
        "\n",
        "            n_matching = len(set(truth) & set(prediction))\n",
        "            precision = n_matching / k\n",
        "            recall = n_matching / len(truth)\n",
        "\n",
        "            total_precision.append(precision)\n",
        "            total_recall.append(recall)\n",
        "        \n",
        "    print(f'Train Precision@{k}: {np.mean(total_precision)} \\nTrain Recall@{k}: {np.mean(total_recall)} \\nTrain Shape: {sparse_matrix.getnnz()}')\n",
        "        \n",
        "    \n",
        "    ### TEST\n",
        "    values = np.ones(model.test.shape[0])\n",
        "    users = model.test.loc[:, 'user_id']\n",
        "    items = model.test.loc[:, 'item_id']\n",
        "    \n",
        "    sparse_matrix = sp.csr_matrix((values, (users, items)))\n",
        "    \n",
        "    matrix = sparse_matrix.toarray()\n",
        "    total_precision = []\n",
        "    total_recall = []\n",
        "    \n",
        "    for index, row in enumerate(matrix):\n",
        "        \n",
        "        truth = np.nonzero(row)[0]\n",
        "        if len(truth) > 0:\n",
        "            prediction = np.argsort(-model.pred[index, :])[:k]\n",
        "\n",
        "            n_matching = len(set(truth) & set(prediction))\n",
        "            precision = n_matching / k\n",
        "            recall = n_matching / len(truth)\n",
        "\n",
        "            total_precision.append(precision)\n",
        "            total_recall.append(recall)\n",
        "        \n",
        "    print(f'\\nTest Precision@{k}: {np.mean(total_precision)} \\nTest Recall@{k}: {np.mean(total_recall)} \\nTest Shape: {sparse_matrix.getnnz()}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaAZhILlPmP4"
      },
      "source": [
        "### Model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DFmHnUNPfdH"
      },
      "source": [
        "class ScaledEmbedding(torch.nn.Embedding):\n",
        "    \"\"\"\n",
        "    Embedding layer that initialises its values\n",
        "    to using a normal variable scaled by the inverse\n",
        "    of the embedding dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        self.weight.data.normal_(0, 1.0 / self.embedding_dim)\n",
        "        if self.padding_idx is not None:\n",
        "            self.weight.data[self.padding_idx].fill_(0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mfsFpKRPijh"
      },
      "source": [
        "class ZeroEmbedding(torch.nn.Embedding):\n",
        "    \"\"\"\n",
        "    Embedding layer that initialises its values\n",
        "    to using a normal variable scaled by the inverse\n",
        "    of the embedding dimension.\n",
        "    Used for biases.\n",
        "    \"\"\"\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        self.weight.data.zero_()\n",
        "        if self.padding_idx is not None:\n",
        "            self.weight.data[self.padding_idx].fill_(0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggjFhDEuPlGA"
      },
      "source": [
        "class Miner(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, dataset, n_factors, net_type, use_metadata, use_cuda=False):\n",
        "        super().__init__()\n",
        "             \n",
        "        self.dataset = dataset\n",
        "        self.n_users = dataset.dataset['user_id'].max() + 1\n",
        "        self.n_items = dataset.dataset['item_id'].max() + 1\n",
        "        self.dictionary = dataset.get_item_metadata_dict()\n",
        "        self.n_metadata = self._get_n_metadata(self.dataset)\n",
        "        \n",
        "        self.n_factors = n_factors\n",
        "        \n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        self.net_type = net_type\n",
        "        self.use_metadata = use_metadata\n",
        "\n",
        "        self._init_net(net_type=net_type)\n",
        "\n",
        "    \n",
        "    def _get_n_metadata(self, dataset):\n",
        "        \n",
        "        n_metadata = 0\n",
        "        \n",
        "        for col in dataset.metadata_id:\n",
        "            n_metadata += dataset.dataset[col].max() + 1\n",
        "        \n",
        "        return n_metadata\n",
        "\n",
        "    \n",
        "    def _init_net(self, net_type='lightfm'):\n",
        "\n",
        "        if net_type == 'lightfm':\n",
        "          print('Training LightFM')\n",
        "          self.net = LightFM(n_users=self.n_users, \n",
        "                              n_items=self.n_items, \n",
        "                              n_metadata=self.n_metadata, \n",
        "                              n_factors=self.n_factors, \n",
        "                              use_metadata=self.use_metadata, \n",
        "                              use_cuda=self.use_cuda)\n",
        "        else:\n",
        "          print('under_construction')\n",
        "          #net = MLP(n_users, n_items, n_metadata, n_metadata_type, n_factors, use_metadata=True, use_cuda=False)\n",
        "        \n",
        "\n",
        "    def forward(self, net, batch, batch_size):\n",
        "\n",
        "        score = gpu(net.forward(batch, batch_size), self.use_cuda)\n",
        "\n",
        "        return score\n",
        "    \n",
        "    \n",
        "    def backward(self, positive, negative, optimizer):\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        loss_value = hinge_loss(positive, negative)                \n",
        "\n",
        "        loss_value.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        return loss_value.item()\n",
        "    \n",
        "    \n",
        "    def fit(self, optimizer, batch_size=1024, epochs=10, split_train_test=False, verbose=False):\n",
        "        \n",
        "        if split_train_test:\n",
        "            \n",
        "            print('|== Splitting Train/Test ==|')\n",
        "            \n",
        "            data = self.dataset.dataset.iloc[np.random.permutation(len(self.dataset.dataset))]\n",
        "            train = data.iloc[:int(len(data) * 0.9)]\n",
        "            test = data.iloc[int(len(data) * 0.9):]\n",
        "            \n",
        "            print(f'Shape Train: {len(train)} \\nShape Test: {len(test)}')\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            train = self.dataset.dataset\n",
        "        \n",
        "        \n",
        "        self.total_train_auc = []\n",
        "        self.total_test_auc = []\n",
        "        self.total_loss = []\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            print(f'Epoch: {epoch+1}')\n",
        "            \n",
        "            epoch_loss = []\n",
        "\n",
        "            for first in range(0, len(train), batch_size):\n",
        "                \n",
        "                batch = train.iloc[first:first+batch_size, :]\n",
        "                \n",
        "                positive = self.forward(net=self.net, batch=batch, batch_size=batch_size)\n",
        "\n",
        "                neg_batch = get_negative_batch(batch, self.n_items, self.dictionary)\n",
        "                negative = self.forward(net=self.net, batch=neg_batch, batch_size=batch_size)     \n",
        "                                                                \n",
        "                loss_value = self.backward(positive, negative, optimizer)\n",
        "                \n",
        "            epoch_loss.append(loss_value)\n",
        "            self.total_loss.append(epoch_loss)\n",
        "            \n",
        "            \n",
        "            if verbose:\n",
        "                ### AUC Calc.\n",
        "                ### Train\n",
        "                train_sample = train.sample(n=20_000)\n",
        "\n",
        "                positive_train = self.forward(net=self.net, batch=train_sample, batch_size=len(train_sample))\n",
        "\n",
        "                neg_batch = get_negative_batch(train_sample, self.n_items, self.dictionary)  \n",
        "                negative_train = self.forward(net=self.net, batch=neg_batch, batch_size=len(train_sample))           \n",
        "                \n",
        "                train_auc = auc_score(positive_train, negative_train)\n",
        "                self.total_train_auc.append(train_auc)\n",
        "                \n",
        "                ### Test\n",
        "                test_sample = test.sample(n=20_000) \n",
        "                \n",
        "                positive_test = self.forward(net=self.net, batch=test_sample, batch_size=len(test_sample))\n",
        "\n",
        "                neg_batch = get_negative_batch(test_sample, self.n_items, self.dictionary)\n",
        "                negative_test = self.forward(net=self.net, batch=neg_batch, batch_size=len(test_sample))   \n",
        "\n",
        "                test_auc = auc_score(positive_test, negative_test)\n",
        "                self.total_test_auc.append(test_auc)\n",
        "                \n",
        "                print(f'== Loss: {sum(epoch_loss)} \\n== Train AUC: {train_auc} \\n== Test AUC: {test_auc}')\n",
        "            \n",
        "    def history(self):\n",
        "        \n",
        "        return {'train_loss': self.total_loss,\n",
        "                'train_auc': self.total_train_auc,\n",
        "                'test_auc': self.total_test_auc}\n",
        "    \n",
        "    def get_item_representation(self):\n",
        "        \n",
        "        return self.item.weight.cpu().detach().numpy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLVlJDL-PsCS"
      },
      "source": [
        "class LightFM(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, n_users, n_items, n_metadata, n_factors, use_metadata=True, use_cuda=False):\n",
        "        super(LightFM, self).__init__()\n",
        "\n",
        "        self.n_users = n_users\n",
        "        self.n_items = n_items\n",
        "        self.n_metadata = n_metadata\n",
        "        \n",
        "        self.n_factors = n_factors\n",
        "        \n",
        "        self.use_metadata = use_metadata\n",
        "        self.use_cuda = use_cuda\n",
        "        \n",
        "        if use_metadata:\n",
        "            self.n_metadata = self.n_metadata\n",
        "            self.metadata = gpu(ScaledEmbedding(self.n_metadata, n_factors), self.use_cuda)\n",
        "\n",
        "        \n",
        "        self.user = gpu(ScaledEmbedding(self.n_users, self.n_factors), self.use_cuda)\n",
        "        self.item = gpu(ScaledEmbedding(self.n_items, self.n_factors), self.use_cuda)\n",
        "        \n",
        "        self.user_bias = gpu(ZeroEmbedding(self.n_users, 1), self.use_cuda)\n",
        "        self.item_bias = gpu(ZeroEmbedding(self.n_items, 1), self.use_cuda)\n",
        "    \n",
        "    \n",
        "    def forward(self, batch, batch_size):\n",
        "        \n",
        "        \"\"\"\n",
        "        Forward method that express the model as the dot product of user and item embeddings, plus the biases. \n",
        "        Item Embeddings itself is the sum of the embeddings of the item ID and its metadata\n",
        "        \"\"\"\n",
        "        \n",
        "        user = Variable(gpu(torch.LongTensor(batch['user_id'].values), self.use_cuda))\n",
        "        item = Variable(gpu(torch.LongTensor(batch['item_id'].values), self.use_cuda))\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            metadata = Variable(gpu(torch.LongTensor(list(batch['metadata'])), self.use_cuda))\n",
        "            metadata = self.metadata(metadata)\n",
        "\n",
        "        user_bias = self.user_bias(user)\n",
        "        item_bias = self.item_bias(item)\n",
        "        \n",
        "        user = self.user(user)\n",
        "        item = self.item(item)\n",
        "        \n",
        "        if self.use_metadata:\n",
        "        \n",
        "            ### Reshaping in order to match metadata tensor\n",
        "            item = item.reshape(len(batch['item_id'].values), 1, self.n_factors)        \n",
        "            item_metadata = torch.cat([item, metadata], axis=1)\n",
        "\n",
        "            ### sum of latent dimensions\n",
        "            item = item_metadata.sum(1)\n",
        "        \n",
        "        net = (user * item).sum(1).view(-1,1) + user_bias + item_bias\n",
        "        \n",
        "        return net\n",
        "    \n",
        "    def get_item_representation(self):\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            \n",
        "            data = (self.dataset\n",
        "                    .dataset[['item_id'] + self.dataset.metadata_id]\n",
        "                    .drop_duplicates())\n",
        "            \n",
        "            mapping = pd.get_dummies(data, columns=[*self.dataset.metadata_id]).values[:, 1:]\n",
        "            identity = np.identity(self.dataset.dataset['item_id'].max() + 1)\n",
        "            binary = np.hstack([identity, mapping])\n",
        "            \n",
        "            metadata_representation = np.vstack([self.item.weight.detach().numpy(), self.metadata.weight.detach().numpy()])\n",
        "            \n",
        "            return np.dot(binary, metadata_representation), binary, metadata_representation\n",
        "        \n",
        "        else:\n",
        "            return self.item.weight.cpu().detach().numpy()\n",
        "        \n",
        "        \n",
        "    def predict(self, user_idx):\n",
        "        \n",
        "        \"\"\"\n",
        "        It takes a user vector representation (based on user_idx arg) and it takes the dot product with\n",
        "        the item representation\n",
        "        \"\"\"\n",
        "        \n",
        "        item_repr, _, _ = self.get_item_representation()\n",
        "        user_repr = self.user.weight.detach().numpy()\n",
        "        \n",
        "        item_bias = self.item_bias.weight.detach().numpy()\n",
        "        user_bias = self.user_bias[torch.tensor([user_idx])].detach().numpy()\n",
        "        \n",
        "        return np.dot(user_pred[user_idx, :], item_repr) + item_bias + user_bias"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCVIuFwIPun0"
      },
      "source": [
        "class MLP(torch.nn.Module):\n",
        "\n",
        "    ### UNDER COSTRUCTION\n",
        "    \n",
        "    def __init__(self, n_users, n_items, n_metadata, n_metadata_type, n_factors, use_metadata=True, use_cuda=False):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        self.use_metadata = use_metadata\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        if use_metadata:\n",
        "            self.n_metadata = n_metadata\n",
        "            self.n_metadata_type = n_metadata_type\n",
        "            self.metadata = gpu(ScaledEmbedding(self.n_metadata, n_factors), self.use_cuda)\n",
        "            \n",
        "        else:\n",
        "            self.n_metadata_type = 0\n",
        "        \n",
        "        self.linear_1 = gpu(torch.nn.Linear(n_factors*(2+self.n_metadata_type), int(self.n_factors/2)), self.use_cuda)\n",
        "        self.linear_2 = gpu(torch.nn.Linear(int(self.n_factors/2), int(self.n_factors/4)), self.use_cuda)\n",
        "        self.linear_3 = gpu(torch.nn.Linear(int(self.n_factors/4), 1), self.use_cuda)\n",
        "        \n",
        "    def _get_n_metadata(self, dataset):\n",
        "        \n",
        "        n_metadata = 0\n",
        "        \n",
        "        for col in dataset.metadata_id:\n",
        "            n_metadata += dataset.dataset[col].max() + 1\n",
        "        \n",
        "        return n_metadata\n",
        "    \n",
        "    def _get_n_metadata_type(self, dataset):\n",
        "        \n",
        "        return len(dataset.metadata)\n",
        "    \n",
        "    \n",
        "    def mlp(self, dataset, batch_size=1):\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        user = gpu(torch.from_numpy(dataset['user_id'].values), self.use_cuda)\n",
        "        item = gpu(torch.from_numpy(dataset['item_id'].values), self.use_cuda)\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            metadata = Variable(gpu(torch.LongTensor(list(dataset['metadata'])), self.use_cuda))\n",
        "            metadata = self.metadata(metadata).reshape(batch_size, self.n_factors*self.n_metadata_type)\n",
        "            \n",
        "        user = self.user(user)\n",
        "        item = self.item(item)\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            cat = torch.cat([user, item, metadata], axis=1).reshape(batch_size, (2+self.n_metadata_type)*self.n_factors)\n",
        "        else:\n",
        "            cat = torch.cat([user, item], axis=1).reshape(batch_size, 2*self.n_factors)\n",
        "                \n",
        "        net = self.linear_1(cat)\n",
        "        net = torch.nn.functional.relu(net)\n",
        "        \n",
        "        net = self.linear_2(net)\n",
        "        net = torch.nn.functional.relu(net)\n",
        "        \n",
        "        net = self.linear_3(net)\n",
        "        \n",
        "        return net\n",
        "    \n",
        "    def forward(self, dataset, batch_size=1):\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        \n",
        "        net = gpu(self.mlp(dataset, batch_size), self.use_cuda)\n",
        "                \n",
        "        return net\n",
        "    \n",
        "    def get_item_representation(self):\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            \n",
        "            data = (self.dataset\n",
        "                    .dataset[['item_id'] + self.dataset.metadata_id]\n",
        "                    .drop_duplicates())\n",
        "            \n",
        "            mapping = pd.get_dummies(data, columns=[*self.dataset.metadata_id]).values[:, 1:]\n",
        "            identity = np.identity(self.dataset.dataset['item_id'].max() + 1)\n",
        "            binary = np.hstack([identity, mapping])\n",
        "            \n",
        "            metadata_representation = np.vstack([self.item.weight.detach().numpy(), self.metadata.weight.detach().numpy()])\n",
        "            \n",
        "            return np.dot(binary, metadata_representation), binary, metadata_representation\n",
        "        \n",
        "        else:\n",
        "            return self.item.weight.cpu().detach().numpy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkRQhNzNPwnw"
      },
      "source": [
        "class NeuCF(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, dataset, n_factors, use_metadata=True):\n",
        "        super().__init__(dataset, n_factors)\n",
        "        \n",
        "        self.use_metadata = use_metadata\n",
        "        \n",
        "        if use_metadata:\n",
        "            self.n_metadata = self._get_n_metadata(dataset)\n",
        "            self.n_metadata_type = self._get_n_metadata_type(dataset)\n",
        "            self.metadata_gmf = ScaledEmbedding(self.n_metadata, n_factors)\n",
        "            self.metadata_mlp = ScaledEmbedding(self.n_metadata, n_factors)\n",
        "            \n",
        "        else:\n",
        "            self.n_metadata_type = 0\n",
        "    \n",
        "        self.user_gmf = ScaledEmbedding(self.n_users, self.n_factors)\n",
        "        self.user_mlp = ScaledEmbedding(self.n_users, self.n_factors)\n",
        "        \n",
        "        self.item_gmf = ScaledEmbedding(self.n_items, self.n_factors)\n",
        "        self.item_mlp = ScaledEmbedding(self.n_items, self.n_factors)\n",
        "        \n",
        "        self.linear_1 = torch.nn.Linear(n_factors*(2+self.n_metadata_type), self.n_factors*4)\n",
        "        self.linear_2 = torch.nn.Linear(self.n_factors*4, self.n_factors*2)\n",
        "        self.linear_3 = torch.nn.Linear(self.n_factors*2, self.n_factors)\n",
        "        self.linear_4 = torch.nn.Linear(self.n_factors*2, 1)\n",
        "        \n",
        "        self.weights = torch.nn.Parameter(torch.rand(2), requires_grad=True)\n",
        "        \n",
        "    def _get_n_metadata(self, dataset):\n",
        "        \n",
        "        n_metadata = 0\n",
        "        \n",
        "        for col in dataset.metadata_id:\n",
        "            n_metadata += dataset.dataset[col].max() + 1\n",
        "        \n",
        "        return n_metadata\n",
        "    \n",
        "    def _get_n_metadata_type(self, dataset):\n",
        "        \n",
        "        return len(dataset.metadata)\n",
        "    \n",
        "        \n",
        "    def gmf(self, dataset, batch_size=1):\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        \n",
        "        user = Variable(torch.LongTensor(dataset['user_id'].values))\n",
        "        item = Variable(torch.LongTensor(dataset['item_id'].values))\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            metadata = Variable(torch.LongTensor(list(dataset['metadata'])))\n",
        "            metadata = self.metadata_gmf(metadata)\n",
        "            \n",
        "        user = self.user_gmf(user)\n",
        "        item = self.item_gmf(item)\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            item = item.reshape(batch_size, 1, self.n_factors)        \n",
        "            item_metadata = torch.cat([item, metadata], axis=1)\n",
        "\n",
        "            ### sum of latent dimensions\n",
        "            item = item_metadata.sum(1)\n",
        "        \n",
        "        #net = (user * item).sum(1).view(-1,1) \n",
        "        net = (user * item)\n",
        "        \n",
        "        return net\n",
        "    \n",
        "    def mlp(self, dataset, batch_size=1):\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        user = Variable(torch.LongTensor(dataset['user_id'].values))\n",
        "        item = Variable(torch.LongTensor(dataset['item_id'].values))\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            metadata = Variable(torch.LongTensor(list(dataset['metadata'])))\n",
        "            metadata = self.metadata_mlp(metadata).reshape(batch_size, self.n_factors*self.n_metadata_type)\n",
        "            \n",
        "        user = self.user_mlp(user)\n",
        "        item = self.item_mlp(item)\n",
        "        \n",
        "        if self.use_metadata:\n",
        "            cat = torch.cat([user, item, metadata], axis=1).reshape(batch_size, (2+self.n_metadata_type)*self.n_factors)\n",
        "        else:\n",
        "            cat = torch.cat([user, item], axis=1).reshape(batch_size, 2*self.n_factors)\n",
        "                \n",
        "        net = self.linear_1(cat)\n",
        "        net = torch.nn.functional.relu(net)\n",
        "        \n",
        "        net = self.linear_2(net)\n",
        "        net = torch.nn.functional.relu(net)\n",
        "        \n",
        "        net = self.linear_3(net)\n",
        "        \n",
        "        return net\n",
        "    \n",
        "    def forward(self, dataset, batch_size=1):\n",
        "        \n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        user = Variable(torch.LongTensor(dataset['user_id'].values))\n",
        "        item = Variable(torch.LongTensor(dataset['item_id'].values))\n",
        "        \n",
        "        gmf = self.gmf(dataset, batch_size)\n",
        "        mlp = self.mlp(dataset, batch_size)\n",
        "        \n",
        "        net = torch.cat([gmf, mlp], axis=1)\n",
        "        \n",
        "        net = self.linear_4(net)\n",
        "#        net = torch.nn.functional.sigmoid(net)\n",
        "#         net = (self.weights * net).sum(1)\n",
        "                \n",
        "        return net"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jxRxBm2PyZy"
      },
      "source": [
        "class EASE():\n",
        "    \n",
        "    def __init__(self, dataset, split_train_test=True):\n",
        "        \n",
        "        self.dataset = dataset\n",
        "        self.item_dict = dataset.dataset.set_index('item_id')['product'].to_dict()\n",
        "        self.split_train_test = split_train_test\n",
        "        self._split_train_test()\n",
        "        \n",
        "    \n",
        "    def _split_train_test(self):\n",
        "        \n",
        "        if self.split_train_test:\n",
        "        \n",
        "            print('|== Splitting Train/Test ==|')\n",
        "            \n",
        "            data = self.dataset.dataset.iloc[np.random.permutation(len(self.dataset.dataset))]\n",
        "            self.train = data.iloc[:int(len(data) * 0.9)]\n",
        "            self.test = data.iloc[int(len(data) * 0.9):]\n",
        "            \n",
        "            print(f'Shape Train: {len(self.train)} \\nShape Test: {len(self.test)}')\n",
        "            \n",
        "        else:\n",
        "            \n",
        "            self.train = self.dataset.dataset\n",
        "            \n",
        "    \n",
        "    def fit(self, lambda_: float = 0.5, implicit=True):\n",
        "        \n",
        "        if implicit:\n",
        "            values = np.ones(self.train.shape[0])\n",
        "        else:\n",
        "            values = self.train.loc[:, 'action']\n",
        "        \n",
        "        users = self.train.loc[:, 'user_id']\n",
        "        items = self.train.loc[:, 'item_id']\n",
        "        \n",
        "        matrix = sp.csr_matrix((values, (users, items)))\n",
        "        self.matrix = matrix\n",
        "        \n",
        "        ### Weight Bij are\n",
        "        ### 0s if i=j (diagonal)\n",
        "        ### -Pij / Pjj otherwise\n",
        "        ### where P = Xt * X - lambda*I\n",
        "        \n",
        "        g = matrix.T.dot(matrix).toarray() \n",
        "        \n",
        "        diagonal = np.diag_indices(g.shape[0])\n",
        "        g[diagonal] += lambda_ ### => gives P\n",
        "        \n",
        "        p = np.linalg.inv(g)\n",
        "        \n",
        "        b = p / (-np.diag(p)) ### => gives Bij\n",
        "        b[diagonal] = 0       ### and sets diagonal to 0\n",
        "        \n",
        "        self.b = b\n",
        "        self.pred = matrix.dot(b)\n",
        "        \n",
        "    \n",
        "    def predict(self, user_id, k):\n",
        "        \n",
        "        user_prediction = self.pred[user_id, :]\n",
        "        item_ranked = np.argsort(-user_prediction)[:k]\n",
        "        \n",
        "        item_ranked = [self.item_dict[item] for item in item_ranked]\n",
        "        \n",
        "        return item_ranked\n",
        "    \n",
        "    \n",
        "    def get_similarity(self, k=10):\n",
        "        \n",
        "        similarity = {}\n",
        "        \n",
        "        for idx, row in enumerate(self.b):\n",
        "            \n",
        "            sorted_index = np.argsort(-row)[:k]\n",
        "            sorted_codes = [self.item_dict[item] for item in sorted_index]\n",
        "            similarity.update({self.item_dict[idx]: sorted_codes})\n",
        "            \n",
        "        return similarity"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do1mhHKSP0Ee"
      },
      "source": [
        "### Main"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCM0v3pdQnPs"
      },
      "source": [
        "dataset = Dataset(brand='ton')\n",
        "dataset.fit(metadata=['saleLine'])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjAa6grZOlgg"
      },
      "source": [
        "config = {'model': ['lightfm'],\n",
        "          'metadata': [True, False],\n",
        "          'n_factors': [128, 64],\n",
        "          'lr': [1e-2, 1e-3],\n",
        "          'batch_size': [51_200]}\n",
        "\n",
        "is_verbose=True\n",
        "epochs=20"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j0RV-wWQYTR"
      },
      "source": [
        "import datetime"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD9RUnU7OzkU",
        "outputId": "02777456-3f09-4d57-b25d-2c23898a835f"
      },
      "source": [
        "performance = None\n",
        "id = 0\n",
        "\n",
        "for model in config['model']:\n",
        "  for is_metadata in config['metadata']:\n",
        "    for factors in config['n_factors']:\n",
        "      for lr in config['lr']:\n",
        "        for batch_size in config['batch_size']:\n",
        "\n",
        "          print(f'Model: {model}, \\nMetadata: {is_metadata}, \\nFactors: {factors} \\nLR: {lr}, \\nBatch Size: {batch_size}')\n",
        "          start = datetime.datetime.now()\n",
        "\n",
        "          if model == 'lightfm':\n",
        "\n",
        "            modello = Miner(dataset=dataset,\n",
        "                            n_factors=factors,\n",
        "                            use_metadata=is_metadata,\n",
        "                            net_type='lightfm',\n",
        "                            use_cuda=True)\n",
        "            \n",
        "          else: \n",
        "\n",
        "            modello = Miner(dataset=dataset,\n",
        "                            n_factors=factors,\n",
        "                            use_metadata=is_metadata,\n",
        "                            net_type='mlp',\n",
        "                            use_cuda=True)\n",
        "                        \n",
        "          optimizer_model = torch.optim.Adam(modello.net.parameters(), \n",
        "                                             lr=lr)\n",
        "          \n",
        "          modello.fit(optimizer=optimizer_model, \n",
        "                      batch_size=batch_size, \n",
        "                      epochs=epochs, \n",
        "                      split_train_test=True,\n",
        "                      verbose=is_verbose)\n",
        "          \n",
        "          end = datetime.datetime.now()\n",
        "          runtime = (end - start).seconds\n",
        "\n",
        "          print(f'\\n Runtime: {runtime} \\n')\n",
        "\n",
        "          id += 1\n",
        "          \n",
        "          single = pd.DataFrame({'id': id,\n",
        "                                'model': model,\n",
        "                                'use_metadata': is_metadata,\n",
        "                                'factors': factors,\n",
        "                                'lr': [lr],\n",
        "                                'batch_size': [batch_size],\n",
        "                                'train_AUC': modello.history()['train_auc'][epochs-1],\n",
        "                                'test_AUC': modello.history()['test_auc'][epochs-1],\n",
        "                                'history_train_AUC': [modello.history()['train_auc']],\n",
        "                                'history_test_AUC': [modello.history()['test_auc']],\n",
        "                                'runtime': [runtime]})\n",
        "          \n",
        "          performance = pd.concat([performance, single])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: lightfm, \n",
            "Metadata: True, \n",
            "Factors: 128 \n",
            "LR: 0.01, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.17334800958633423 \n",
            "== Train AUC: 0.96865 \n",
            "== Test AUC: 0.9346\n",
            "Epoch: 2\n",
            "== Loss: 0.06908554583787918 \n",
            "== Train AUC: 0.98295 \n",
            "== Test AUC: 0.9436\n",
            "Epoch: 3\n",
            "== Loss: 0.04899083450436592 \n",
            "== Train AUC: 0.9861 \n",
            "== Test AUC: 0.95035\n",
            "Epoch: 4\n",
            "== Loss: 0.04147815331816673 \n",
            "== Train AUC: 0.9862 \n",
            "== Test AUC: 0.95185\n",
            "Epoch: 5\n",
            "== Loss: 0.039015062153339386 \n",
            "== Train AUC: 0.98735 \n",
            "== Test AUC: 0.95095\n",
            "Epoch: 6\n",
            "== Loss: 0.03590443357825279 \n",
            "== Train AUC: 0.98725 \n",
            "== Test AUC: 0.95145\n",
            "Epoch: 7\n",
            "== Loss: 0.033245544880628586 \n",
            "== Train AUC: 0.98745 \n",
            "== Test AUC: 0.9514\n",
            "Epoch: 8\n",
            "== Loss: 0.03382667154073715 \n",
            "== Train AUC: 0.9891 \n",
            "== Test AUC: 0.94995\n",
            "Epoch: 9\n",
            "== Loss: 0.030395057052373886 \n",
            "== Train AUC: 0.9905 \n",
            "== Test AUC: 0.95405\n",
            "Epoch: 10\n",
            "== Loss: 0.03202332928776741 \n",
            "== Train AUC: 0.9901 \n",
            "== Test AUC: 0.95225\n",
            "Epoch: 11\n",
            "== Loss: 0.030314553529024124 \n",
            "== Train AUC: 0.98915 \n",
            "== Test AUC: 0.95255\n",
            "Epoch: 12\n",
            "== Loss: 0.02700483612716198 \n",
            "== Train AUC: 0.99005 \n",
            "== Test AUC: 0.9557\n",
            "Epoch: 13\n",
            "== Loss: 0.027507642284035683 \n",
            "== Train AUC: 0.99065 \n",
            "== Test AUC: 0.95195\n",
            "Epoch: 14\n",
            "== Loss: 0.030869536101818085 \n",
            "== Train AUC: 0.99015 \n",
            "== Test AUC: 0.9523\n",
            "Epoch: 15\n",
            "== Loss: 0.026905100792646408 \n",
            "== Train AUC: 0.98985 \n",
            "== Test AUC: 0.95235\n",
            "Epoch: 16\n",
            "== Loss: 0.03027590923011303 \n",
            "== Train AUC: 0.9901 \n",
            "== Test AUC: 0.95385\n",
            "Epoch: 17\n",
            "== Loss: 0.028098179027438164 \n",
            "== Train AUC: 0.9911 \n",
            "== Test AUC: 0.9522\n",
            "Epoch: 18\n",
            "== Loss: 0.02805223874747753 \n",
            "== Train AUC: 0.99055 \n",
            "== Test AUC: 0.9509\n",
            "Epoch: 19\n",
            "== Loss: 0.029653992503881454 \n",
            "== Train AUC: 0.99075 \n",
            "== Test AUC: 0.95165\n",
            "Epoch: 20\n",
            "== Loss: 0.029511606320738792 \n",
            "== Train AUC: 0.99235 \n",
            "== Test AUC: 0.9496\n",
            "\n",
            " Runtime: 413 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: True, \n",
            "Factors: 128 \n",
            "LR: 0.001, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.6603022217750549 \n",
            "== Train AUC: 0.9223 \n",
            "== Test AUC: 0.8971\n",
            "Epoch: 2\n",
            "== Loss: 0.2641800343990326 \n",
            "== Train AUC: 0.941 \n",
            "== Test AUC: 0.91745\n",
            "Epoch: 3\n",
            "== Loss: 0.15222688019275665 \n",
            "== Train AUC: 0.9599 \n",
            "== Test AUC: 0.9321\n",
            "Epoch: 4\n",
            "== Loss: 0.10951987653970718 \n",
            "== Train AUC: 0.97035 \n",
            "== Test AUC: 0.9369\n",
            "Epoch: 5\n",
            "== Loss: 0.08184107393026352 \n",
            "== Train AUC: 0.97485 \n",
            "== Test AUC: 0.94395\n",
            "Epoch: 6\n",
            "== Loss: 0.07086947560310364 \n",
            "== Train AUC: 0.97925 \n",
            "== Test AUC: 0.94655\n",
            "Epoch: 7\n",
            "== Loss: 0.06011204048991203 \n",
            "== Train AUC: 0.98295 \n",
            "== Test AUC: 0.95015\n",
            "Epoch: 8\n",
            "== Loss: 0.05186525732278824 \n",
            "== Train AUC: 0.9847 \n",
            "== Test AUC: 0.9504\n",
            "Epoch: 9\n",
            "== Loss: 0.04768146574497223 \n",
            "== Train AUC: 0.98635 \n",
            "== Test AUC: 0.95295\n",
            "Epoch: 10\n",
            "== Loss: 0.04159874841570854 \n",
            "== Train AUC: 0.988 \n",
            "== Test AUC: 0.9526\n",
            "Epoch: 11\n",
            "== Loss: 0.038301799446344376 \n",
            "== Train AUC: 0.9884 \n",
            "== Test AUC: 0.9517\n",
            "Epoch: 12\n",
            "== Loss: 0.034165091812610626 \n",
            "== Train AUC: 0.98845 \n",
            "== Test AUC: 0.95235\n",
            "Epoch: 13\n",
            "== Loss: 0.03365412354469299 \n",
            "== Train AUC: 0.98965 \n",
            "== Test AUC: 0.9551\n",
            "Epoch: 14\n",
            "== Loss: 0.030391184613108635 \n",
            "== Train AUC: 0.98875 \n",
            "== Test AUC: 0.953\n",
            "Epoch: 15\n",
            "== Loss: 0.03130178526043892 \n",
            "== Train AUC: 0.991 \n",
            "== Test AUC: 0.956\n",
            "Epoch: 16\n",
            "== Loss: 0.027562052011489868 \n",
            "== Train AUC: 0.99035 \n",
            "== Test AUC: 0.9557\n",
            "Epoch: 17\n",
            "== Loss: 0.02662159688770771 \n",
            "== Train AUC: 0.9906 \n",
            "== Test AUC: 0.9567\n",
            "Epoch: 18\n",
            "== Loss: 0.027414172887802124 \n",
            "== Train AUC: 0.99055 \n",
            "== Test AUC: 0.959\n",
            "Epoch: 19\n",
            "== Loss: 0.024409247562289238 \n",
            "== Train AUC: 0.99225 \n",
            "== Test AUC: 0.95915\n",
            "Epoch: 20\n",
            "== Loss: 0.02224968746304512 \n",
            "== Train AUC: 0.99325 \n",
            "== Test AUC: 0.96075\n",
            "\n",
            " Runtime: 412 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: True, \n",
            "Factors: 64 \n",
            "LR: 0.01, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.19393467903137207 \n",
            "== Train AUC: 0.9587 \n",
            "== Test AUC: 0.92505\n",
            "Epoch: 2\n",
            "== Loss: 0.08378487825393677 \n",
            "== Train AUC: 0.9752 \n",
            "== Test AUC: 0.94225\n",
            "Epoch: 3\n",
            "== Loss: 0.05764206871390343 \n",
            "== Train AUC: 0.9819 \n",
            "== Test AUC: 0.9432\n",
            "Epoch: 4\n",
            "== Loss: 0.04699151590466499 \n",
            "== Train AUC: 0.9848 \n",
            "== Test AUC: 0.94625\n",
            "Epoch: 5\n",
            "== Loss: 0.0409800186753273 \n",
            "== Train AUC: 0.98695 \n",
            "== Test AUC: 0.95265\n",
            "Epoch: 6\n",
            "== Loss: 0.03793459013104439 \n",
            "== Train AUC: 0.98785 \n",
            "== Test AUC: 0.9509\n",
            "Epoch: 7\n",
            "== Loss: 0.03428144007921219 \n",
            "== Train AUC: 0.98825 \n",
            "== Test AUC: 0.953\n",
            "Epoch: 8\n",
            "== Loss: 0.03470619022846222 \n",
            "== Train AUC: 0.98805 \n",
            "== Test AUC: 0.9545\n",
            "Epoch: 9\n",
            "== Loss: 0.03171428292989731 \n",
            "== Train AUC: 0.98865 \n",
            "== Test AUC: 0.95505\n",
            "Epoch: 10\n",
            "== Loss: 0.031631067395210266 \n",
            "== Train AUC: 0.98955 \n",
            "== Test AUC: 0.9591\n",
            "Epoch: 11\n",
            "== Loss: 0.028747813776135445 \n",
            "== Train AUC: 0.9881 \n",
            "== Test AUC: 0.952\n",
            "Epoch: 12\n",
            "== Loss: 0.027968380600214005 \n",
            "== Train AUC: 0.98915 \n",
            "== Test AUC: 0.95505\n",
            "Epoch: 13\n",
            "== Loss: 0.0264945887029171 \n",
            "== Train AUC: 0.9895 \n",
            "== Test AUC: 0.9554\n",
            "Epoch: 14\n",
            "== Loss: 0.02797222137451172 \n",
            "== Train AUC: 0.98895 \n",
            "== Test AUC: 0.95375\n",
            "Epoch: 15\n",
            "== Loss: 0.02869526669383049 \n",
            "== Train AUC: 0.9911 \n",
            "== Test AUC: 0.95655\n",
            "Epoch: 16\n",
            "== Loss: 0.026946816593408585 \n",
            "== Train AUC: 0.99075 \n",
            "== Test AUC: 0.9581\n",
            "Epoch: 17\n",
            "== Loss: 0.029248524457216263 \n",
            "== Train AUC: 0.98895 \n",
            "== Test AUC: 0.9561\n",
            "Epoch: 18\n",
            "== Loss: 0.0237551499158144 \n",
            "== Train AUC: 0.9908 \n",
            "== Test AUC: 0.95305\n",
            "Epoch: 19\n",
            "== Loss: 0.024328891187906265 \n",
            "== Train AUC: 0.9901 \n",
            "== Test AUC: 0.9577\n",
            "Epoch: 20\n",
            "== Loss: 0.026548834517598152 \n",
            "== Train AUC: 0.9914 \n",
            "== Test AUC: 0.95455\n",
            "\n",
            " Runtime: 352 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: True, \n",
            "Factors: 64 \n",
            "LR: 0.001, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.810455858707428 \n",
            "== Train AUC: 0.90155 \n",
            "== Test AUC: 0.88825\n",
            "Epoch: 2\n",
            "== Loss: 0.38953638076782227 \n",
            "== Train AUC: 0.929 \n",
            "== Test AUC: 0.9051\n",
            "Epoch: 3\n",
            "== Loss: 0.21962060034275055 \n",
            "== Train AUC: 0.9486 \n",
            "== Test AUC: 0.91845\n",
            "Epoch: 4\n",
            "== Loss: 0.1540829986333847 \n",
            "== Train AUC: 0.95825 \n",
            "== Test AUC: 0.92315\n",
            "Epoch: 5\n",
            "== Loss: 0.12035844475030899 \n",
            "== Train AUC: 0.96525 \n",
            "== Test AUC: 0.93355\n",
            "Epoch: 6\n",
            "== Loss: 0.09906954318284988 \n",
            "== Train AUC: 0.9733 \n",
            "== Test AUC: 0.93415\n",
            "Epoch: 7\n",
            "== Loss: 0.08525621891021729 \n",
            "== Train AUC: 0.97495 \n",
            "== Test AUC: 0.94185\n",
            "Epoch: 8\n",
            "== Loss: 0.07291611284017563 \n",
            "== Train AUC: 0.97975 \n",
            "== Test AUC: 0.9405\n",
            "Epoch: 9\n",
            "== Loss: 0.06497921049594879 \n",
            "== Train AUC: 0.9805 \n",
            "== Test AUC: 0.9456\n",
            "Epoch: 10\n",
            "== Loss: 0.06004076078534126 \n",
            "== Train AUC: 0.98145 \n",
            "== Test AUC: 0.94695\n",
            "Epoch: 11\n",
            "== Loss: 0.05651464685797691 \n",
            "== Train AUC: 0.98165 \n",
            "== Test AUC: 0.94855\n",
            "Epoch: 12\n",
            "== Loss: 0.051580071449279785 \n",
            "== Train AUC: 0.98475 \n",
            "== Test AUC: 0.9499\n",
            "Epoch: 13\n",
            "== Loss: 0.04759475588798523 \n",
            "== Train AUC: 0.98615 \n",
            "== Test AUC: 0.95\n",
            "Epoch: 14\n",
            "== Loss: 0.0437336266040802 \n",
            "== Train AUC: 0.9848 \n",
            "== Test AUC: 0.9486\n",
            "Epoch: 15\n",
            "== Loss: 0.04149278625845909 \n",
            "== Train AUC: 0.98525 \n",
            "== Test AUC: 0.9503\n",
            "Epoch: 16\n",
            "== Loss: 0.03935655206441879 \n",
            "== Train AUC: 0.9874 \n",
            "== Test AUC: 0.95325\n",
            "Epoch: 17\n",
            "== Loss: 0.03874338045716286 \n",
            "== Train AUC: 0.98805 \n",
            "== Test AUC: 0.9534\n",
            "Epoch: 18\n",
            "== Loss: 0.03685793653130531 \n",
            "== Train AUC: 0.98755 \n",
            "== Test AUC: 0.95165\n",
            "Epoch: 19\n",
            "== Loss: 0.03369049355387688 \n",
            "== Train AUC: 0.988 \n",
            "== Test AUC: 0.95285\n",
            "Epoch: 20\n",
            "== Loss: 0.03317511826753616 \n",
            "== Train AUC: 0.9891 \n",
            "== Test AUC: 0.95485\n",
            "\n",
            " Runtime: 352 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: False, \n",
            "Factors: 128 \n",
            "LR: 0.01, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.30776599049568176 \n",
            "== Train AUC: 0.93955 \n",
            "== Test AUC: 0.8866\n",
            "Epoch: 2\n",
            "== Loss: 0.07778286933898926 \n",
            "== Train AUC: 0.98315 \n",
            "== Test AUC: 0.93145\n",
            "Epoch: 3\n",
            "== Loss: 0.04763776808977127 \n",
            "== Train AUC: 0.98765 \n",
            "== Test AUC: 0.93685\n",
            "Epoch: 4\n",
            "== Loss: 0.03495202213525772 \n",
            "== Train AUC: 0.9899 \n",
            "== Test AUC: 0.9387\n",
            "Epoch: 5\n",
            "== Loss: 0.032193418592214584 \n",
            "== Train AUC: 0.99065 \n",
            "== Test AUC: 0.9435\n",
            "Epoch: 6\n",
            "== Loss: 0.02841581031680107 \n",
            "== Train AUC: 0.9919 \n",
            "== Test AUC: 0.94225\n",
            "Epoch: 7\n",
            "== Loss: 0.02680625207722187 \n",
            "== Train AUC: 0.99195 \n",
            "== Test AUC: 0.9403\n",
            "Epoch: 8\n",
            "== Loss: 0.026649951934814453 \n",
            "== Train AUC: 0.99045 \n",
            "== Test AUC: 0.94255\n",
            "Epoch: 9\n",
            "== Loss: 0.023877054452896118 \n",
            "== Train AUC: 0.9915 \n",
            "== Test AUC: 0.9443\n",
            "Epoch: 10\n",
            "== Loss: 0.025569267570972443 \n",
            "== Train AUC: 0.9921 \n",
            "== Test AUC: 0.94265\n",
            "Epoch: 11\n",
            "== Loss: 0.023587018251419067 \n",
            "== Train AUC: 0.99195 \n",
            "== Test AUC: 0.94115\n",
            "Epoch: 12\n",
            "== Loss: 0.02405376173555851 \n",
            "== Train AUC: 0.99225 \n",
            "== Test AUC: 0.94125\n",
            "Epoch: 13\n",
            "== Loss: 0.02282528206706047 \n",
            "== Train AUC: 0.9924 \n",
            "== Test AUC: 0.9432\n",
            "Epoch: 14\n",
            "== Loss: 0.023540792986750603 \n",
            "== Train AUC: 0.9916 \n",
            "== Test AUC: 0.94215\n",
            "Epoch: 15\n",
            "== Loss: 0.022876106202602386 \n",
            "== Train AUC: 0.99205 \n",
            "== Test AUC: 0.9419\n",
            "Epoch: 16\n",
            "== Loss: 0.023328270763158798 \n",
            "== Train AUC: 0.992 \n",
            "== Test AUC: 0.9408\n",
            "Epoch: 17\n",
            "== Loss: 0.02525731921195984 \n",
            "== Train AUC: 0.9919 \n",
            "== Test AUC: 0.94015\n",
            "Epoch: 18\n",
            "== Loss: 0.02456388622522354 \n",
            "== Train AUC: 0.9927 \n",
            "== Test AUC: 0.94055\n",
            "Epoch: 19\n",
            "== Loss: 0.022769808769226074 \n",
            "== Train AUC: 0.99185 \n",
            "== Test AUC: 0.94205\n",
            "Epoch: 20\n",
            "== Loss: 0.02264748141169548 \n",
            "== Train AUC: 0.99045 \n",
            "== Test AUC: 0.94285\n",
            "\n",
            " Runtime: 308 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: False, \n",
            "Factors: 128 \n",
            "LR: 0.001, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.9171400666236877 \n",
            "== Train AUC: 0.84715 \n",
            "== Test AUC: 0.83335\n",
            "Epoch: 2\n",
            "== Loss: 0.502669095993042 \n",
            "== Train AUC: 0.88185 \n",
            "== Test AUC: 0.86425\n",
            "Epoch: 3\n",
            "== Loss: 0.3046042323112488 \n",
            "== Train AUC: 0.91245 \n",
            "== Test AUC: 0.8942\n",
            "Epoch: 4\n",
            "== Loss: 0.21660998463630676 \n",
            "== Train AUC: 0.9379 \n",
            "== Test AUC: 0.91465\n",
            "Epoch: 5\n",
            "== Loss: 0.16043202579021454 \n",
            "== Train AUC: 0.9557 \n",
            "== Test AUC: 0.93415\n",
            "Epoch: 6\n",
            "== Loss: 0.1246742457151413 \n",
            "== Train AUC: 0.96555 \n",
            "== Test AUC: 0.9438\n",
            "Epoch: 7\n",
            "== Loss: 0.10002540051937103 \n",
            "== Train AUC: 0.9732 \n",
            "== Test AUC: 0.9525\n",
            "Epoch: 8\n",
            "== Loss: 0.08199302852153778 \n",
            "== Train AUC: 0.9779 \n",
            "== Test AUC: 0.95625\n",
            "Epoch: 9\n",
            "== Loss: 0.06954286992549896 \n",
            "== Train AUC: 0.98125 \n",
            "== Test AUC: 0.96065\n",
            "Epoch: 10\n",
            "== Loss: 0.06002495810389519 \n",
            "== Train AUC: 0.9828 \n",
            "== Test AUC: 0.9606\n",
            "Epoch: 11\n",
            "== Loss: 0.05303562059998512 \n",
            "== Train AUC: 0.9847 \n",
            "== Test AUC: 0.9618\n",
            "Epoch: 12\n",
            "== Loss: 0.04761241376399994 \n",
            "== Train AUC: 0.9877 \n",
            "== Test AUC: 0.96385\n",
            "Epoch: 13\n",
            "== Loss: 0.04194969683885574 \n",
            "== Train AUC: 0.98955 \n",
            "== Test AUC: 0.9663\n",
            "Epoch: 14\n",
            "== Loss: 0.037062741816043854 \n",
            "== Train AUC: 0.9883 \n",
            "== Test AUC: 0.966\n",
            "Epoch: 15\n",
            "== Loss: 0.03501584380865097 \n",
            "== Train AUC: 0.99175 \n",
            "== Test AUC: 0.96735\n",
            "Epoch: 16\n",
            "== Loss: 0.0313318707048893 \n",
            "== Train AUC: 0.99045 \n",
            "== Test AUC: 0.9691\n",
            "Epoch: 17\n",
            "== Loss: 0.0294635072350502 \n",
            "== Train AUC: 0.992 \n",
            "== Test AUC: 0.969\n",
            "Epoch: 18\n",
            "== Loss: 0.027999861165881157 \n",
            "== Train AUC: 0.99155 \n",
            "== Test AUC: 0.97045\n",
            "Epoch: 19\n",
            "== Loss: 0.02477535419166088 \n",
            "== Train AUC: 0.9937 \n",
            "== Test AUC: 0.96955\n",
            "Epoch: 20\n",
            "== Loss: 0.024761781096458435 \n",
            "== Train AUC: 0.99305 \n",
            "== Test AUC: 0.97155\n",
            "\n",
            " Runtime: 308 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: False, \n",
            "Factors: 64 \n",
            "LR: 0.01, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.3472432792186737 \n",
            "== Train AUC: 0.90885 \n",
            "== Test AUC: 0.87425\n",
            "Epoch: 2\n",
            "== Loss: 0.11087456345558167 \n",
            "== Train AUC: 0.9736 \n",
            "== Test AUC: 0.92995\n",
            "Epoch: 3\n",
            "== Loss: 0.06185434013605118 \n",
            "== Train AUC: 0.98175 \n",
            "== Test AUC: 0.93615\n",
            "Epoch: 4\n",
            "== Loss: 0.04930552467703819 \n",
            "== Train AUC: 0.98415 \n",
            "== Test AUC: 0.94085\n",
            "Epoch: 5\n",
            "== Loss: 0.039682649075984955 \n",
            "== Train AUC: 0.98675 \n",
            "== Test AUC: 0.94575\n",
            "Epoch: 6\n",
            "== Loss: 0.033361129462718964 \n",
            "== Train AUC: 0.98755 \n",
            "== Test AUC: 0.94435\n",
            "Epoch: 7\n",
            "== Loss: 0.03145797550678253 \n",
            "== Train AUC: 0.98875 \n",
            "== Test AUC: 0.94835\n",
            "Epoch: 8\n",
            "== Loss: 0.03171945735812187 \n",
            "== Train AUC: 0.98895 \n",
            "== Test AUC: 0.94475\n",
            "Epoch: 9\n",
            "== Loss: 0.02594592049717903 \n",
            "== Train AUC: 0.9902 \n",
            "== Test AUC: 0.945\n",
            "Epoch: 10\n",
            "== Loss: 0.028377674520015717 \n",
            "== Train AUC: 0.98995 \n",
            "== Test AUC: 0.94505\n",
            "Epoch: 11\n",
            "== Loss: 0.026478897780179977 \n",
            "== Train AUC: 0.9906 \n",
            "== Test AUC: 0.9463\n",
            "Epoch: 12\n",
            "== Loss: 0.026154128834605217 \n",
            "== Train AUC: 0.9907 \n",
            "== Test AUC: 0.947\n",
            "Epoch: 13\n",
            "== Loss: 0.026329968124628067 \n",
            "== Train AUC: 0.99035 \n",
            "== Test AUC: 0.94585\n",
            "Epoch: 14\n",
            "== Loss: 0.024522121995687485 \n",
            "== Train AUC: 0.99025 \n",
            "== Test AUC: 0.94505\n",
            "Epoch: 15\n",
            "== Loss: 0.025726040825247765 \n",
            "== Train AUC: 0.9905 \n",
            "== Test AUC: 0.9473\n",
            "Epoch: 16\n",
            "== Loss: 0.023973172530531883 \n",
            "== Train AUC: 0.99065 \n",
            "== Test AUC: 0.94715\n",
            "Epoch: 17\n",
            "== Loss: 0.023097122088074684 \n",
            "== Train AUC: 0.9909 \n",
            "== Test AUC: 0.9483\n",
            "Epoch: 18\n",
            "== Loss: 0.0242563895881176 \n",
            "== Train AUC: 0.9898 \n",
            "== Test AUC: 0.94615\n",
            "Epoch: 19\n",
            "== Loss: 0.024248208850622177 \n",
            "== Train AUC: 0.99155 \n",
            "== Test AUC: 0.9463\n",
            "Epoch: 20\n",
            "== Loss: 0.022622568532824516 \n",
            "== Train AUC: 0.99235 \n",
            "== Test AUC: 0.9464\n",
            "\n",
            " Runtime: 248 \n",
            "\n",
            "Model: lightfm, \n",
            "Metadata: False, \n",
            "Factors: 64 \n",
            "LR: 0.001, \n",
            "Batch Size: 51200\n",
            "Training LightFM\n",
            "|== Splitting Train/Test ==|\n",
            "Shape Train: 6493380 \n",
            "Shape Test: 721487\n",
            "Epoch: 1\n",
            "== Loss: 0.9226212501525879 \n",
            "== Train AUC: 0.8353 \n",
            "== Test AUC: 0.82645\n",
            "Epoch: 2\n",
            "== Loss: 0.7871668934822083 \n",
            "== Train AUC: 0.8554 \n",
            "== Test AUC: 0.84415\n",
            "Epoch: 3\n",
            "== Loss: 0.46518319845199585 \n",
            "== Train AUC: 0.8774 \n",
            "== Test AUC: 0.86155\n",
            "Epoch: 4\n",
            "== Loss: 0.3277636766433716 \n",
            "== Train AUC: 0.90695 \n",
            "== Test AUC: 0.88645\n",
            "Epoch: 5\n",
            "== Loss: 0.2503906488418579 \n",
            "== Train AUC: 0.92775 \n",
            "== Test AUC: 0.91165\n",
            "Epoch: 6\n",
            "== Loss: 0.1953870803117752 \n",
            "== Train AUC: 0.9427 \n",
            "== Test AUC: 0.9256\n",
            "Epoch: 7\n",
            "== Loss: 0.1557271033525467 \n",
            "== Train AUC: 0.95365 \n",
            "== Test AUC: 0.93285\n",
            "Epoch: 8\n",
            "== Loss: 0.12850141525268555 \n",
            "== Train AUC: 0.96425 \n",
            "== Test AUC: 0.9403\n",
            "Epoch: 9\n",
            "== Loss: 0.1101103127002716 \n",
            "== Train AUC: 0.9676 \n",
            "== Test AUC: 0.9465\n",
            "Epoch: 10\n",
            "== Loss: 0.09582996368408203 \n",
            "== Train AUC: 0.97165 \n",
            "== Test AUC: 0.9511\n",
            "Epoch: 11\n",
            "== Loss: 0.08219648152589798 \n",
            "== Train AUC: 0.97735 \n",
            "== Test AUC: 0.9544\n",
            "Epoch: 12\n",
            "== Loss: 0.0739956870675087 \n",
            "== Train AUC: 0.98 \n",
            "== Test AUC: 0.95635\n",
            "Epoch: 13\n",
            "== Loss: 0.06877070665359497 \n",
            "== Train AUC: 0.9798 \n",
            "== Test AUC: 0.9556\n",
            "Epoch: 14\n",
            "== Loss: 0.059817757457494736 \n",
            "== Train AUC: 0.9821 \n",
            "== Test AUC: 0.96005\n",
            "Epoch: 15\n",
            "== Loss: 0.05649643391370773 \n",
            "== Train AUC: 0.98475 \n",
            "== Test AUC: 0.9644\n",
            "Epoch: 16\n",
            "== Loss: 0.05141444131731987 \n",
            "== Train AUC: 0.98595 \n",
            "== Test AUC: 0.9636\n",
            "Epoch: 17\n",
            "== Loss: 0.047240398824214935 \n",
            "== Train AUC: 0.9881 \n",
            "== Test AUC: 0.96325\n",
            "Epoch: 18\n",
            "== Loss: 0.043100617825984955 \n",
            "== Train AUC: 0.98715 \n",
            "== Test AUC: 0.9635\n",
            "Epoch: 19\n",
            "== Loss: 0.042187053710222244 \n",
            "== Train AUC: 0.9897 \n",
            "== Test AUC: 0.96455\n",
            "Epoch: 20\n",
            "== Loss: 0.03963807225227356 \n",
            "== Train AUC: 0.98805 \n",
            "== Test AUC: 0.96545\n",
            "\n",
            " Runtime: 247 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAuvpJZVtmWP"
      },
      "source": [
        "best_performing = performance.sort_values('test_AUC', ascending=False).head(4)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "V2XCOTQO2gVr",
        "outputId": "279ff1bd-a2dc-4624-a801-ae3a70d8f1dc"
      },
      "source": [
        "best_performing"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model</th>\n",
              "      <th>use_metadata</th>\n",
              "      <th>factors</th>\n",
              "      <th>lr</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>train_AUC</th>\n",
              "      <th>test_AUC</th>\n",
              "      <th>history_train_AUC</th>\n",
              "      <th>history_test_AUC</th>\n",
              "      <th>runtime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>lightfm</td>\n",
              "      <td>False</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001</td>\n",
              "      <td>51200</td>\n",
              "      <td>0.99305</td>\n",
              "      <td>0.97155</td>\n",
              "      <td>[0.84715, 0.88185, 0.91245, 0.9379, 0.9557, 0....</td>\n",
              "      <td>[0.83335, 0.86425, 0.8942, 0.91465, 0.93415, 0...</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>lightfm</td>\n",
              "      <td>False</td>\n",
              "      <td>64</td>\n",
              "      <td>0.001</td>\n",
              "      <td>51200</td>\n",
              "      <td>0.98805</td>\n",
              "      <td>0.96545</td>\n",
              "      <td>[0.8353, 0.8554, 0.8774, 0.90695, 0.92775, 0.9...</td>\n",
              "      <td>[0.82645, 0.84415, 0.86155, 0.88645, 0.91165, ...</td>\n",
              "      <td>247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>lightfm</td>\n",
              "      <td>True</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001</td>\n",
              "      <td>51200</td>\n",
              "      <td>0.99325</td>\n",
              "      <td>0.96075</td>\n",
              "      <td>[0.9223, 0.941, 0.9599, 0.97035, 0.97485, 0.97...</td>\n",
              "      <td>[0.8971, 0.91745, 0.9321, 0.9369, 0.94395, 0.9...</td>\n",
              "      <td>412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>lightfm</td>\n",
              "      <td>True</td>\n",
              "      <td>64</td>\n",
              "      <td>0.001</td>\n",
              "      <td>51200</td>\n",
              "      <td>0.98910</td>\n",
              "      <td>0.95485</td>\n",
              "      <td>[0.90155, 0.929, 0.9486, 0.95825, 0.96525, 0.9...</td>\n",
              "      <td>[0.88825, 0.9051, 0.91845, 0.92315, 0.93355, 0...</td>\n",
              "      <td>352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    model  ...                                   history_test_AUC  runtime\n",
              "0   6  lightfm  ...  [0.83335, 0.86425, 0.8942, 0.91465, 0.93415, 0...      308\n",
              "0   8  lightfm  ...  [0.82645, 0.84415, 0.86155, 0.88645, 0.91165, ...      247\n",
              "0   2  lightfm  ...  [0.8971, 0.91745, 0.9321, 0.9369, 0.94395, 0.9...      412\n",
              "0   4  lightfm  ...  [0.88825, 0.9051, 0.91845, 0.92315, 0.93355, 0...      352\n",
              "\n",
              "[4 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "BSgHh68_sf2D",
        "outputId": "0b36cf6d-a725-482e-d165-ea5b9497ec2e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for idx, row in best_performing.iterrows():\n",
        "  plt.plot(range(20), row['history_test_AUC'], label=f\"Metadata: {row['use_metadata']}, Factors: {row['factors']}, LR: {row['lr']}, Runtime: {row['runtime']}s\")\n",
        "  plt.legend()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}